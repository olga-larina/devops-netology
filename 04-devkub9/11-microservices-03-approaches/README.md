# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

### Ответ
Сейчас большинство современных программных продуктов удовлетворяют перечисленным требованиям. Опишу решение, которое используется 
у нас на работе.
- Bitbucket - для хранения исходного кода, управления репозиториями. Предоставляет неограниченный объём закрытых репозиториев, 
интегрируется с JIRA, предоставляет возможности встроенного CI/CD или использования других инструментов.
- Teamcity - для тестирования и сборок. Интегрируется с Bitbucket, позволяет запускать тесты и сборки по коммитам, PR и мерджам. Активно развивается, есть 
множество плагинов, удобный build log.
- JFrog в качестве артифактори. Teamcity кладёт туда собранные артефакты.

Общий процесс следующий: Вносятся изменения в код и делается PR в Bitbucket. Выполняется автоматическое тестирование в Teamcity. 
После мерджа также выполняется тестирование + выполняется сборка артефактов, которые размещаются в JFrog. Далее может, например, 
происходить разворачивание только что собранного сервиса в Kubernetes.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

### Ответ

Стандартно это ELK-стек. Работает "из коробки", относительно простой, гибкий. Позволяет реализовать архитектуру hot-warm
(hot - хранение и сбор "быстрых" данных логирования, warm - "медленных" + можно использовать "cold" узлы для архивных данных).

- Filebeat - собирает логи из файлов для последующей отправки в logstash/elasticsearch.
- Logstash - инструмент для приёма данных, преобразования и отправки в elasticsearch. Позволяет парсить входные данные, дополнительно 
обрабатывать, форматировать. В нём есть возможности различных фильтров.
- Elasticsearch - инструмент полнотекстового поиска, позволяет быстро обрабатывать большие объёмы данных. 
- Kibana - средство визуализации логов. Можно выводить текстовые данные, сортировать, фильтровать, агрегировать, строить графики, диаграммы.


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

### Ответ

- Prometheus - система для сбора метрик. В его основе pull-метод. Дополнительно есть компонент Pushgateway, куда могут пушить метрики короткоживущие job-ы.
Однако оттуда метрики забираются pull-методом, как и из обычных job-ов и exporter-ов. Это коробочная система, можно использовать без
дополнительных инструментов. Состоит из нескольких компонентов - Exporter (агент для сборки метрик с хост-машин и хранения до сбора системой мониторинга),
Server (хранение и управление данными), WEB UI (для доступа к данным и конфигурирования), Alert manager (оповещение). 
При настройке для Server компонента нужно указать узлы для сбора метрик (т.к. pull-модель).
- Node exporter подходит для сбора метрик состояния хостов.
- Специфичные метрики должны быть стандартизированы (наименование, единицы измерения). У нас используется библиотека micrometer для сбора метрик приложений.
- Для построения графиков и визуализации будет удобна Graphana. Она легко интегрируется с различными источниками данных (например, 
Prometheus), есть различные плагины, уже готовые дашборды для наборов метрик, системы оповещения, удобный язык запросов.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
