# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1

Составьте постмортем на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

## Задача повышенной сложности

Прослушайте [симуляцию аудиозаписи о инциденте](https://youtu.be/vw6I5DYWkNA?t=1), предоставленную 
разработчиками инструмента для автоматизации инцидент-менеджмента PagerDuty.

На основании этой аудиозаписи попробуйте составить сообщения для пользователей о данном инциденте.

Должно быть 3 сообщения о:
- начале инцидента
- продолжающихся работах
- окончании инцидента и возвращении к штатной работе

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

### Ответ
#### Краткое описание инцидента
21 октября 2018 произошёл кратковременный сетевой сбой, приведший к несогласованности данных в БД. 
Это привело к снижению качества обслуживания на 24 часа 11 минут. Была затронута работа некоторых служб, что привело 
к отображению несогласованной информации. В итоге пользовательские данные потеряны не были

#### Предшествующие события
Были регламентные работы по замене вышедшего из строя оптического оборудования

#### Причина инцидента
В результате регламентных работ потеряна связь между сетевым концентратором US East Coast и основным дата-центром US East Coast. 
Она была восстановлена за 43 секунды, но кратковременный сбой привёл к несогласованности данных в БД.

#### Воздействие
Отображение несогласованной и устаревшей информации. Не работали веб-хуки и публикация GitHub Pages.

#### Обнаружение
Обнаружено инженерами, обрабатывающими предупреждения мониторингов, когда стали появляться ошибки о массовом сбое и несогласованности 
топологии кластера БД.

#### Реакция
Для решения инцидента привлечены различные команды. Полностью восстановить работу удалось за 24 часа (с учётом продолжительного восстановления из резервных копий).

#### Восстановление
Остановлены сборки, проведено восстановление из резервных копий БД, реплицированы новые данные, выполнено переключение на исходную топологию, обработаны ожидающие сборки.

#### Таймлайн
2018 год
- 21 октября 22:52 UTC - Из-за указанного сбоя Оркестратор начал процесс перестроения кластера БД MySQL. И записи начались в US West Coast. 
При этом в US East Coast остались записи, которые не были реплицированы в US West Coast. Таким образом, образовалась несогласованность данных, что 
привело к невозможности возврата к US East Coast как основному дата-центру.
- 21 октября 22:54 UTC - Предупреждения систем мониторинга. В 23:02 инженеры определили, что топология кластеров БД находится в 
несогласованном состоянии - там были только сервера из US West Coast.
- 21 октября 23:07 UTC - Вручную заблокирован внутренний инструмент развёртывания, чтобы предотвратить внесение каких-либо изменений. 
Сайт переведён в жёлтый статус, автоматически создан инцидент и направлен координатору. В 23:11 координатор проставил красный статус.
- 21 октября 23:13 UTC - Вызваны дополнительные инженеры, которые начали исследовать проблему. Данные в US West Coast и US East Coast не 
были согласованы. Т.к. главный приоритет - это сохранность данных, требовалось восстановить целостность. Деградация продолжилась,
в приложениях в US East Coast была большая задержка из-за обмена данных с US West Coast.
- 21 октября 23:19 UTC - Остановлены некоторые процессы (типа записи метаданных об уведомлениях), чтобы не подвергать опасности данные.
- 22 октября 00:05 UTC - Инженеры начали разработку плана по устранению несогласованности. План состоял в восстановлении из резервных копий, 
синхронизации реплик, возврат к стабильной топологии, возобновление обработки заданий в очереди. Обновлён статус для пользователей. Процесс 
восстановления занял несколько часов из-за переноса данных из удалённой службы, распаковки, проверки контрольных сумм и загрузки файлов.
- 22 октября 00:41 UTC - Инициирован процесс резервного копирования, инженеры следили за его ходом. Другие инженеры искали способы ускорить 
процесс.
- 22 октября 06:51 UTC - Несколько кластеров завершили процесс восстановления в US East Coast и начали репликацию новых данных с US West Coast.  
Из-за этого - медленная загрузка страниц, но актуальные результаты, если запрос попадал на восстановленную реплику. Более крупные кластеры 
ещё восстанавливались. Обновлена страница состояния.
- 22 октября 07:46 UTC - Опубликовано сообщение в блоге.
- 22 октября 11:12 UTC - Все primary ноды снова в US East Coast. Улучшена работоспособность сайта, т.к. сервер БД и приложений в одном и том же ЦОД. 
Но всё равно существовали реплики, отстающие на несколько часов. Из-за этого пользователи могли видеть несогласованные данные. Время восстановления 
увеличилось из-за повышения нагрузки (начался рабочий день).
- 22 октября 13:15 UTC - Задержки репликации увеличиваются из-за повышения нагрузки. Для снятия нагрузки - распределение запросов на чтение 
по большему количеству серверов. 
- 22 октября 16:24 UTC - Реплики синхронизированы, аварийное переключение на исходную топологию.
- 22 октября 16:45 UTC - Восстановление данных (хуки, сборки). После включения обработки этих данных возросла нагрузка, увеличили TTL.
- 22 октября 23:03 UTC - Все ожидающие сборки обработаны, восстановлена целостность системы. Статус обновлён до зелёного

#### Последующие действия
- Устранение несоответствий данных - анализируются журналы MySQL в части тех записей, которые были сделаны в US East Coast, но не были 
реплицированы. Определяется, какие записи можно восстановить автоматически, а для каких потребуется взаимодействие с пользователями.  
Технические инициативы:
- Настройка конфигурации Оркестратора, чтобы primary ноды выбирались в том же регионе (иначе приложение не справляется).
- Новый механизм состояний, чтобы было понятно, что именно происходит. До этого было только 3 варианта - зелёный, жёлтый, красный, хотя большая часть 
функционала работала.
- Работы по поддержке обслуживания трафика из нескольких ЦОД, чтобы отказ одного из ЦОД не оказывал влияния на пользователей.