# Olga Ivanova, devops-10. Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её
нужно прервать.

Вы, как инженер поддержки, решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

### Ответ

Сначала найдём нужный запрос и его ID (данная команда покажет активные операции в базе `db1`, которые длятся более 3 секунд):  
```text
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 3 },
     "ns" : /^db1\./
   }
)
```

А потом убьём его по ID:  
```text
db.killOp(opid)
```

Для решения проблемы с долгими запросами нужно:  
- найти эти запросы. Для этого включить профайлинг, например: `db.setProfilingLevel(2)`; проанализировать результат, например, найти запросы, длящиеся больше 500мс:  
```text
db.system.profile
  .find({ millis: { $gt: 500 }})
  .pretty()
```
- посмотреть их план выполнения `.explain("executionStats")`  
- создать соответствующие индексы  
- можно ещё задавать таймаут выполнения запроса с помощью опции `maxTimeMS`  

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL.
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

### Ответ

Дополнительно использован материал из [статьи](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/improving-key-expiration-in-redis).

У Redis есть 2 механизма экспирации:  
- ленивый: проверка на экспирацию осуществляется только при обращении к ключу.  
- активный: проверка осуществляется каждые 100 мс, если в выборке из `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` ключей найдено более 25% истёкших ключей, процесс повторяется.
В случае активного механизма Redis может блокироваться, если много ключей истекают одновременно и цикл экспирации повторяется много раз.

Судя по всему, у нас происходит следующее. Без масштабирования проверка запускается на выборке из небольшого количества ключей (`ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` по умолчанию равно 20). 
И находит в ней меньше 25% истёкших ключей, экспирирует их и дальше не продолжает. А при масштабировании до N реплик в выборке из такого же количества ключей находит больше 25%
(т.к. всего ключей на каждой реплике меньше, поэтому вероятность выбрать истёкшие больше) и запускает цикл. Видимо, у нас в одно и то же время истекает много ключей, просто без масштабирования 
они не находятся. А при масштабировании цикл повторяется несколько раз, из-за чего происходит блокировка операций записи.  
Чтобы решить проблему, нужно поэкспериментировать с параметром `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP`.  

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```text
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?
Какие пути решения данной проблемы вы можете предложить?

### Ответ

Есть несколько возможных вариантов:  
- проблемы с сетью (нужно проверить сетевые настройки и качество сети)  
- высокая нагрузка и "тяжёлые", многомиллионные запросы. В таком случае надо увеличить параметр `net_read_timeout`, чтобы было достаточно времени на передачу данных.
- может быть проблема при установлении соединения из-за медленной сети, здесь может помочь увеличение параметра `connect_timeout`. Определить, если ли эта проблема, можно с помощью 
`SHOW GLOBAL STATUS LIKE 'Aborted_connects'`
- BLOB-значения, которые больше `max_allowed_packet`. Поэтому нужно увеличить этот параметр. Сигналом к тому, что у нас такая проблема, будет появление другой ошибки `ER_NET_PACKET_TOO_LARGE`.

## Задача 4

Перед выполнением задания ознакомьтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объемом данных лучше, чем MySQL.
После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:
`postmaster invoked oom-killer`
Как вы думаете, что происходит? Как бы вы решили данную проблему?

### Ответ

Дополнительно использован материал из [статьи](https://habr.com/ru/company/southbridge/blog/464245/).

OOM Killer (out-of memory killer) - по сути, это процесс, который завершает приложение, чтобы спасти ядро ОС от сбоя. 
Если в системе мало памяти и освободить её невозможно, вызывается OOM killer, выбирает процесс по определённым правилам и завершает его. 
Решений здесь несколько:  
- увеличить объём памяти  
- отключить OOM killer (но это не рекомендуется) с помощью параметра `vm.oom-kill`  
- настроить параметр `vm.overcommit_memory`. Linux может зарезервировать для процессов больше памяти, чем есть, но не выделять её по факту, и этим поведением управляет данный параметр. 
Если поставить значение `2`, то ядро не будет резервировать больше памяти, чем указано в параметре `overcommit_ratio`. Это самый безопасный вариант, рекомендованный для PostgreSQL.  
- на OOM killer также влияет возможность подкачки, которой управляет переменная `cat /proc/sys/vm/swappiness`. Чем больше значение, тем меньше вероятности, что OOM завершит процесс, но из-за операций ввода-вывода это негативно сказывается на базе данных.
